{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Project 4 - Advanced Lane Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, we apply advanced Computer Vision techniques to obtain more accurate and robust lane markings in images and video feeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import display, HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_output_dir():\n",
    "    output_dir = './output_images'\n",
    "    \n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "        \n",
    "    return output_dir\n",
    "\n",
    "def get_doc_dir():\n",
    "    output_dir = './res'\n",
    "    \n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "        \n",
    "    return output_dir\n",
    "def save_doc_img(img, name):\n",
    "    mpimg.imsave(os.path.join(get_doc_dir(), name + '.jpg'), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera calibration\n",
    "The first step is to perform camera calibration, to obtain the camera calibration matrix and the distorsion coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract chessboard corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Path to calibration images\n",
    "calibration_images_paths = glob.glob('./camera_cal/*.jpg')\n",
    "\n",
    "# Number of squares in X and Y direction\n",
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "# Define object points for each image. We assume that each square\n",
    "# has a size of 1 meter, and the origin is the top-left corner\n",
    "# of the first square.\n",
    "obj_pts_i = np.zeros((nx*ny, 3), np.float32)\n",
    "obj_pts_i[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "# Declare obj and img points\n",
    "obj_pts = []\n",
    "img_pts = []\n",
    "\n",
    "plotted_img = False\n",
    "\n",
    "# Loop over images\n",
    "for img_path in calibration_images_paths:\n",
    "    # Read image\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Find checkboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "    if ret == True:\n",
    "        # Add points to list\n",
    "        img_pts.append(corners)\n",
    "        obj_pts.append(obj_pts_i)\n",
    "        \n",
    "        # Draw resulting corners for the first image\n",
    "        if not plotted_img:\n",
    "            cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "            plt.imshow(img);\n",
    "            plt.axis('off');\n",
    "            save_doc_img(img, 'checkerboard_corners')\n",
    "            plotted_img = True\n",
    "    else:\n",
    "        print('Warning: could not extract checkboard points from %s.' % img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get calibration coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(obj_pts, img_pts, gray.shape[::-1],None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image undistortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def undistort_img(img):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_img = './camera_cal/calibration1.jpg'\n",
    "img = cv2.imread(test_img)\n",
    "plt.subplot(1,2,1);\n",
    "plt.imshow(img);\n",
    "plt.title('Distorted')\n",
    "plt.axis('off');\n",
    "plt.subplot(1,2,2);\n",
    "img_undistorted = undistort_img(img)\n",
    "plt.imshow(undistort_img(img));\n",
    "plt.title('Undistorted')\n",
    "plt.axis('off');\n",
    "\n",
    "# Save for documentation\n",
    "save_doc_img(img, 'img_distorted')\n",
    "save_doc_img(img_undistorted, 'img_undistorted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask_img(img, thresh):\n",
    "    binary_output = np.zeros_like(img)\n",
    "    binary_output[(img >= thresh[0]) & (img <= thresh[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_sobel(img, orient, sobel_kernel=3):\n",
    "     # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    elif orient == 'y':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    else:\n",
    "        raise NotImplemented\n",
    "    \n",
    "    return sobel\n",
    "\n",
    "def abs_sobel_mask(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Get sobel\n",
    "    sobel = compute_sobel(img, orient)\n",
    "        \n",
    "    # Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    \n",
    "    # Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    # Create a mask of 1's where the scaled gradient magnitude \n",
    "    # is > thresh_min and < thresh_max\n",
    "    return mask_img(scaled_sobel, thresh)\n",
    "    \n",
    "def mag_mask(img, sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Get sobel in X and Y directions\n",
    "    sobel_x = compute_sobel(img, orient = 'x')\n",
    "    sobel_y = compute_sobel(img, orient = 'y')\n",
    "        \n",
    "    # Take the absolute value of the derivative or gradient\n",
    "    sobel_mag = np.sqrt(sobel_x * sobel_x + sobel_y * sobel_y)\n",
    "    \n",
    "    # Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*sobel_mag/np.max(sobel_mag))\n",
    "    \n",
    "    # Create a mask of 1's where the scaled gradient magnitude \n",
    "    # is > thresh_min and < thresh_max\n",
    "    return mask_img(scaled_sobel, thresh)\n",
    "\n",
    "def dir_mask(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Get sobel in X and Y directions\n",
    "    sobel_x = compute_sobel(img, orient = 'x')\n",
    "    sobel_y = compute_sobel(img, orient = 'y')\n",
    "        \n",
    "    # Calculate the absolute direction of the gradient \n",
    "    sobel_dir = np.absolute(np.arctan(sobel_y / (sobel_x + 1.e-7)))\n",
    "\n",
    "    return mask_img(sobel_dir, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_img = './test_images/test1.jpg'\n",
    "img = cv2.imread(test_img)\n",
    "plt.subplot(2,2,1);\n",
    "plt.imshow(abs_sobel_mask(img, orient = 'x', thresh=(5,100)), cmap='gray');\n",
    "plt.axis('off');\n",
    "plt.title('Sobel X');\n",
    "plt.subplot(2,2,2);\n",
    "plt.imshow(abs_sobel_mask(img, orient = 'y', thresh=(5,100)), cmap='gray');\n",
    "plt.axis('off');\n",
    "plt.title('Sobel Y');\n",
    "plt.subplot(2,2,3);\n",
    "plt.imshow(mag_mask(img, thresh=(30,100)), cmap='gray');\n",
    "plt.axis('off');\n",
    "plt.title('Gradient magnitude');\n",
    "plt.subplot(2,2,4);\n",
    "plt.imshow(dir_mask(img, thresh=(0.7, 1.3)), cmap='gray');\n",
    "plt.axis('off');\n",
    "plt.title('Gradient direction');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combined_mask(img):\n",
    "    # Convert to HLS\n",
    "    img_hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    \n",
    "    # Color masks\n",
    "    s_mask = mask_img(img_hls[:,:,2], (90, 255))\n",
    "    # Gradient masks\n",
    "    \n",
    "    # Final mask\n",
    "    mask = s_mask\n",
    "    return s_mask\n",
    "\n",
    "test_img = './test_images/test1.jpg'\n",
    "img = cv2.imread(test_img)\n",
    "plt.imshow(combined_mask(img), cmap='gray');\n",
    "plt.axis('off');\n",
    "plt.title('Final mask');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_img = './test_images/test6.jpg'\n",
    "img = mpimg.imread(test_img) \n",
    "img = undistort_img(img);\n",
    "\n",
    "src_pts_ = ((240, img.shape[0]),\n",
    "           (1200, img.shape[0]),\n",
    "           (765, int(img.shape[0]/1.5)),\n",
    "           (575, int(img.shape[0]/1.5)))\n",
    "\n",
    "offset = 320\n",
    "dst_pts_ = ((offset,              img.shape[0]),\n",
    "           (img.shape[1]-offset, img.shape[0]),\n",
    "           (img.shape[1]-offset, offset),\n",
    "           (offset,              offset))  \n",
    "\n",
    "\n",
    "def get_birds_eye_view(img, src_pts=src_pts_, dst_pts=dst_pts_):\n",
    "    img_size = (img.shape[1], img.shape[0])    \n",
    "   \n",
    "    M    = cv2.getPerspectiveTransform(np.float32(src_pts), np.float32(dst_pts))\n",
    "    Minv = cv2.getPerspectiveTransform(np.float32(dst_pts), np.float32(src_pts))\n",
    "\n",
    "    return cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR), M, Minv\n",
    "\n",
    "\n",
    "img_pts = img.copy()\n",
    "for i in range(4):\n",
    "    img_pts = cv2.line(img_pts, src_pts_[i], src_pts_[(i+1)%4], color=[255,0,0], thickness=4)\n",
    "    \n",
    "    \n",
    "img_warped,_,_ = get_birds_eye_view(img)\n",
    "for i in range(4):\n",
    "    img_warped_pts = cv2.line(img_warped, dst_pts_[i], dst_pts_[(i+1)%4], color=[255,0,0], thickness=4)\n",
    "    \n",
    "plt.figure();\n",
    "plt.imshow(img_pts);\n",
    "plt.title('Original image');\n",
    "plt.figure();\n",
    "plt.imshow(img_warped_pts);\n",
    "plt.title('Warped image');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane pixels detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_img = './test_images/test6.jpg'\n",
    "img_original = mpimg.imread(test_img) \n",
    "img = undistort_img(img_original)\n",
    "img_warped, M, Minv = get_birds_eye_view(img);\n",
    "img_mask = combined_mask(img_warped)\n",
    "\n",
    "def get_starting_x(img, visualize=False):\n",
    "    # Compute histogram\n",
    "    histogram = np.sum(img[int(img.shape[0]/2):,:], axis=0)\n",
    "    \n",
    "    if visualize:\n",
    "        plt.plot(histogram);\n",
    "        plt.autoscale(enable=True, axis='x', tight=True);\n",
    "    \n",
    "    # Get left and right peaks. Assuming that left and right\n",
    "    # lines will be on the left or right half of the image\n",
    "    x_half = int(len(histogram)/2)\n",
    "    x0_left  = np.argmax(histogram[0:x_half])\n",
    "    x0_right = x_half + np.argmax(histogram[x_half:])\n",
    "    \n",
    "    return x0_left, x0_right\n",
    "\n",
    "plt.figure();\n",
    "plt.imshow(img_mask, cmap='gray');\n",
    "plt.title('Masked, warped image');\n",
    "plt.figure();\n",
    "x0_left, x0_right = get_starting_x(img_mask, visualize = True)\n",
    "\n",
    "print('Left line at x = %d, right line at x = %d' % (x0_left, x0_right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self):\n",
    "        # X-Y coordinates of the associated pixels, as a Nx2 vector\n",
    "        self.pixels_x = []\n",
    "        self.pixels_y = []\n",
    "        \n",
    "        # Coefficients describing the line, in pixel coordinates\n",
    "        self.coeffs = [0., 0., 0.]\n",
    "       \n",
    "        # Coefficients describing the line, in meters\n",
    "        self.coeffs_m = [0., 0., 0.]\n",
    "\n",
    "        self.ym_per_pix = 30/720  # meters per pixel in y dimension\n",
    "        self.xm_per_pix = 3.7/700 # meteres per pixel in x dimension\n",
    "        \n",
    "    def fit(self):\n",
    "        if self.pixels_x and self.pixels_y:\n",
    "            # Fit in pixels\n",
    "            self.coeffs = np.polyfit(self.pixels_y, self.pixels_x, 2)\n",
    "\n",
    "            # Fit in meters       \n",
    "            self.coeffs_m = np.polyfit(self.ym_per_pix * np.array(self.pixels_y),\n",
    "                                       self.xm_per_pix * np.array(self.pixels_x), 2)       \n",
    "        \n",
    "    def curvature(self, y_pixels):\n",
    "        y = y_pixels * self.ym_per_pix\n",
    "        \n",
    "        dx_dy   = 2. * self.coeffs_m[0] * y + self.coeffs_m[1]\n",
    "        d2x_dy2 = 2. * self.coeffs_m[0]\n",
    "        \n",
    "        curvature = ((1. + (dx_dy)**2)**1.5) / np.absolute(d2x_dy2)\n",
    "        return curvature\n",
    "    \n",
    "    def get_x_position(self, y_pixels, img_width):\n",
    "        x_pixels = self.coeffs[0]*(y_pixels**2) + self.coeffs[1]*y_pixels + self.coeffs[2] \\\n",
    "                   - float(img_width)/2\n",
    "        return self.xm_per_pix * x_pixels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SlidingWindow():\n",
    "    def __init__(self, size_x, size_y, x0, y0):\n",
    "        self.size_x = size_x\n",
    "        self.size_y = size_y\n",
    "        self.x0 = x0\n",
    "        self.y0 = y0\n",
    "    \n",
    "    def get_pixels(self, img):\n",
    "        pixels_x = []\n",
    "        pixels_y = []\n",
    "        \n",
    "        for x in range(max(0, self.x0), min(img.shape[1], self.x0 + self.size_x)):\n",
    "            for y in range(max(0, self.y0), min(img.shape[0], self.y0 + self.size_y)):\n",
    "                if (img[y, x]):\n",
    "                    pixels_x.append(x)\n",
    "                    pixels_y.append(y)\n",
    "                    \n",
    "        return pixels_x, pixels_y\n",
    "                    \n",
    "    def slide(self, delta_x, delta_y):\n",
    "        self.x0 = self.x0 + delta_x\n",
    "        self.y0 = self.y0 + delta_y\n",
    "                    \n",
    "    def is_point_in_img(self, img, x, y):\n",
    "        if (x >= 0) and (x < img.shape[1]) and \\\n",
    "           (y >= 0) and (y < img.shape[0]):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def is_inside_img(self, img):\n",
    "        if self.is_point_in_img(img, self.x0,               self.y0)               or \\\n",
    "           self.is_point_in_img(img, self.x0 + self.size_x, self.y0)               or \\\n",
    "           self.is_point_in_img(img, self.x0,               self.y0 + self.size_y) or \\\n",
    "           self.is_point_in_img(img, self.x0 + self.size_x, self.y0 + self.size_y):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sliding_window_test(img, x0):\n",
    "    window = SlidingWindow(100, 100, 325, img.shape[0] - 1 - 100)\n",
    "    pixels_x, pixels_y = window.get_pixels(img)\n",
    "   \n",
    "    img_out = np.zeros_like(img)\n",
    "    for i in range(len(pixels_x)):\n",
    "        img_out[pixels_y[i], pixels_x[i]] = 255\n",
    "        \n",
    "    plt.imshow(img_out, cmap='gray')\n",
    "    \n",
    "sliding_window_test(img_mask, 325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_line_pixels(img_masked, x0):\n",
    "    # Initialize sliding window and line\n",
    "    out_line = Line()\n",
    "    size_x = 100\n",
    "    size_y = 100\n",
    "    window = SlidingWindow(size_x, size_y, x0 - size_x//2, img_masked.shape[0] - size_y)\n",
    "    \n",
    "    # Go from bottom to top to find the line:\n",
    "    done = False\n",
    "    while not done:\n",
    "        # Get pixels in the sliding window\n",
    "        pixels_x, pixels_y = window.get_pixels(img_masked)\n",
    "        \n",
    "        # Add to line\n",
    "        out_line.pixels_x = out_line.pixels_x + pixels_x\n",
    "        out_line.pixels_y = out_line.pixels_y + pixels_y\n",
    "        \n",
    "        # Determine where to place the bounding box next\n",
    "        if pixels_x:\n",
    "            min_x = np.amin(pixels_x)            \n",
    "            delta_x = (min_x - window.size_x//2) - window.x0            \n",
    "        else:\n",
    "            # Don't move horizontally if we don't know how the line continues\n",
    "            delta_x = 0\n",
    "        \n",
    "        delta_y = -window.size_y          \n",
    "        \n",
    "        # Move sliding window\n",
    "        window.slide(delta_x, delta_y)\n",
    "        \n",
    "        # We are done if the window is out of the image\n",
    "        if not window.is_inside_img(img_masked):\n",
    "            done = True\n",
    "            \n",
    "    return out_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_line_points(img, line):\n",
    "    n_points = 100\n",
    "    yvals = np.linspace(0, n_points, num=n_points + 1) * (float(img.shape[0]) / float(n_points))\n",
    "    xvals = line.coeffs[0]*yvals**2 + line.coeffs[1]*yvals + line.coeffs[2]   \n",
    "    \n",
    "    return xvals, yvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_line(img, line, color = (255,0,0), thickness = 2):\n",
    "    # Get line points\n",
    "    xvals, yvals = get_line_points(img, line)\n",
    "\n",
    "    # Draw line\n",
    "    for i in range(len(yvals) - 1):\n",
    "        p1 = (int(xvals[i  ]), int(yvals[i  ]))\n",
    "        p2 = (int(xvals[i+1]), int(yvals[i+1]))\n",
    "        \n",
    "        cv2.line(img, p1, p2, color=color, thickness=thickness)   \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_lines(img_mask):\n",
    "    # Get starting position for search\n",
    "    x0_left, x0_right = get_starting_x(img_mask)\n",
    "    \n",
    "    # Search for the line\n",
    "    line_l = get_line_pixels(img_mask, x0_left)\n",
    "    line_r = get_line_pixels(img_mask, x0_right)\n",
    "        \n",
    "    # Fit polynomials to lines\n",
    "    line_l.fit()\n",
    "    line_r.fit()\n",
    "    \n",
    "    return line_l, line_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def line_test(img, x0):\n",
    "    line = get_line_pixels(img, x0)\n",
    "    line.fit()\n",
    "    \n",
    "    img_out = np.zeros_like(img)\n",
    "    for i in range(len(line.pixels_x)):\n",
    "        x = line.pixels_x[i]\n",
    "        y = line.pixels_y[i]\n",
    "\n",
    "        if (y < img.shape[0]) and (x < img.shape[1]):\n",
    "            img_out[y][x] = 255\n",
    "\n",
    "    # Convert to RGB image\n",
    "    img_out = cv2.cvtColor(img_out, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Draw a line representing the fit polynomial\n",
    "    img_out = draw_line(img_out, line)\n",
    "    \n",
    "    plt.figure()            \n",
    "    plt.imshow(img_out)\n",
    "\n",
    "line_test(img_mask, 325)\n",
    "line_test(img_mask, 951)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization in original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_free_space(img, line_left, line_right):\n",
    "    # Get line points\n",
    "    xvals_l, yvals_l = get_line_points(img, line_left)\n",
    "    xvals_r, yvals_r = get_line_points(img, line_right)\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([xvals_l, yvals_l]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([xvals_r, yvals_r])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw into image\n",
    "    cv2.fillPoly(img, np.int_([pts]), (0,255,0))\n",
    "\n",
    "    # Return\n",
    "    return img\n",
    "    \n",
    "line_l = get_line_pixels(img_mask, 325)\n",
    "line_l.fit()\n",
    "\n",
    "line_r = get_line_pixels(img_mask, 951)\n",
    "line_r.fit()\n",
    "\n",
    "img_free_space_test = np.zeros_like(img_mask)\n",
    "img_free_space_test = np.dstack((img_free_space_test, img_free_space_test, img_free_space_test))\n",
    "plt.figure();\n",
    "plt.imshow(draw_free_space(img_free_space_test, line_l, line_r));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_output_img(img_original, line_left, line_right, curvature, lane_offset):\n",
    "    # Copy warped image\n",
    "    img_lines = np.zeros_like(img_original)\n",
    "    img_free_space = np.zeros_like(img_original)\n",
    "\n",
    "    # Draw lines\n",
    "    draw_line(img_lines, line_left, thickness = 50)\n",
    "    draw_line(img_lines, line_right, thickness = 50)    \n",
    "\n",
    "    # Draw free space\n",
    "    draw_free_space(img_free_space, line_left, line_right)\n",
    "    \n",
    "    # Unwarp images\n",
    "    img_free_space_unwarp = cv2.warpPerspective(img_free_space, Minv, (img_original.shape[1], img_original.shape[0])) \n",
    "    img_lines_unwarp = cv2.warpPerspective(img_lines, Minv, (img_original.shape[1], img_original.shape[0])) \n",
    "\n",
    "    # Blend with original image\n",
    "    img_out = cv2.addWeighted(img_original, 1, img_lines_unwarp, 0.3, 0)\n",
    "    img_out = cv2.addWeighted(img_out, 1, img_free_space_unwarp, 0.3, 0)\n",
    "    \n",
    "    # Print curvature and lane offset\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    color = (255, 255, 255)\n",
    "    scale = 2\n",
    "    thickness = 2\n",
    "    cv2.putText(img_out, \"Road curvature: %.1f m\" % curvature, (100, 50), font, scale, color, thickness)\n",
    "    cv2.putText(img_out, \"Offset w.r.t. lane center: %.1f m\" % lane_offset, (100, 100), font, scale, color, thickness)    \n",
    "    \n",
    "    return img_out\n",
    "\n",
    "plt.figure();\n",
    "plt.imshow(generate_output_img(img_original, line_l, line_r, 0, 0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_curvature(line_l, line_r, img_shape):\n",
    "    y_curvature = img_shape[0]\n",
    "    return 0.5 * (line_l.curvature(y_curvature) + line_r.curvature(y_curvature))\n",
    "\n",
    "y_curvature = img_mask.shape[0]\n",
    "print('Curvature - left: %.1f m, right: %.1f m' % (line_l.curvature(y_curvature), line_r.curvature(y_curvature)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Vehicle Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_vehicle_position(line_l, line_r, img_shape):\n",
    "    return 0.5 * (line_r.get_x_position(img_shape[0], img_shape[1]) + \\\n",
    "                  line_l.get_x_position(img_shape[0], img_shape[1]))\n",
    "\n",
    "print('Vehicle position: %.3f m' % compute_vehicle_position(line_l, line_r, img_mask.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_debug_img(result_img, img_warped, img_mask, curvature, vehicle_position):\n",
    "    # Declare output image, full HD\n",
    "    img_out = np.zeros((1080, 1920, 3), dtype = np.uint8)\n",
    "    \n",
    "    # Place images inside img_out\n",
    "    img_out[0:720, 0:1280,     :] = cv2.resize(result_img, (1280, 720))\n",
    "    img_out[720:960, 0:320, :]    = cv2.resize(img_warped, (320,240))\n",
    "    \n",
    "    img_mask = np.dstack((img_mask, img_mask, img_mask)) * 255    \n",
    "    img_out[720:960, 320:640 , :] = cv2.resize(img_mask, (320, 240))\n",
    "    \n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LaneFindingPipeline:\n",
    "    def __init__(self, debug = False):\n",
    "        self.line_l = []\n",
    "        self.line_r = []\n",
    "        self.debug = debug\n",
    "        \n",
    "    def run(self, img):\n",
    "        # Undistort image\n",
    "        img_undistort = undistort_img(img)\n",
    "\n",
    "        # Get birds-eye view\n",
    "        img_warped, M, Minv = get_birds_eye_view(img_undistort);\n",
    "\n",
    "        # Mask using color and gradients\n",
    "        img_mask = combined_mask(img_warped)\n",
    "\n",
    "        # Extract lines\n",
    "        #if not self.line_l or not self.line_r:\n",
    "        self.line_l, self.line_r = extract_lines(img_mask)\n",
    "        #else:\n",
    "        #    print ('TODO: Track line')\n",
    "            #self.line_l, self.line_r = track_lines(self.line_l, self.line_r, img)\n",
    "            \n",
    "        # Compute curvature and vehicle position\n",
    "        curvature = compute_curvature(self.line_l, self.line_r, img.shape)\n",
    "        vehicle_position = compute_vehicle_position(self.line_l, self.line_r, img.shape)\n",
    "\n",
    "        # Create output image\n",
    "        img_out = generate_output_img(img, self.line_l, self.line_r, curvature, vehicle_position)        \n",
    "        \n",
    "        # Return\n",
    "        if self.debug:\n",
    "            img_out = create_debug_img(img_out, img_warped, img_mask, curvature, vehicle_position)\n",
    "            \n",
    "        return img_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_images = glob.glob('./test_images/*.jpg')\n",
    "\n",
    "for img_path in test_images:\n",
    "    _,img_name = os.path.split(img_path)\n",
    "    \n",
    "    # Read image\n",
    "    img = mpimg.imread(img_path)\n",
    "    \n",
    "    # Create a new LaneFindingPipeline\n",
    "    pipeline = LaneFindingPipeline(debug = True)\n",
    "    \n",
    "    # Run it on the image\n",
    "    img_out = pipeline.run(img)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure();\n",
    "    plt.imshow(img_out); \n",
    "    plt.axis('off');\n",
    "    plt.title(img_name);\n",
    "    \n",
    "    # Save to disk\n",
    "    mpimg.imsave(os.path.join(get_output_dir(), img_name), img_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_videos = glob.glob('./*_video.mp4')\n",
    "\n",
    "for video in test_videos:\n",
    "    # Create LaneFindingPipeline\n",
    "    pipeline = LaneFindingPipeline(debug = True)\n",
    "    \n",
    "    # Read video\n",
    "    clip = VideoFileClip(video)\n",
    "    \n",
    "    # Process video\n",
    "    clip_processed = clip.fl_image(pipeline.run) #NOTE: this function expects color images!!\n",
    "    \n",
    "    # Save to disk\n",
    "    _,video_name = os.path.split(video)\n",
    "    out_name = os.path.join(get_output_dir(), video_name)\n",
    "    clip_processed.write_videofile(out_name, audio=False)\n",
    "    \n",
    "    # Display in the notebook\n",
    "    print(out_name)\n",
    "    display(HTML(\"\"\"<video width=\"640\" height=\"360\" controls><source src=\"{0}\"></video>\"\"\".format(out_name)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
